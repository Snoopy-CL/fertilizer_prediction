{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":91717,"databundleVersionId":12184666,"sourceType":"competition"}],"dockerImageVersionId":31040,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom scipy import stats\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\n\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, StratifiedKFold\nfrom sklearn.compose import make_column_transformer, ColumnTransformer\nfrom sklearn.pipeline import Pipeline, make_pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, StandardScaler, LabelEncoder\nfrom category_encoders import TargetEncoder\n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import make_scorer, accuracy_score\nfrom lightgbm import LGBMClassifier","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-28T20:12:29.367893Z","iopub.execute_input":"2025-06-28T20:12:29.368174Z","iopub.status.idle":"2025-06-28T20:12:41.590209Z","shell.execute_reply.started":"2025-06-28T20:12:29.368145Z","shell.execute_reply":"2025-06-28T20:12:41.589395Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Import training and test data\ntrain_df = pd.read_csv('/kaggle/input/playground-series-s5e6/train.csv')\ntest_df = pd.read_csv('/kaggle/input/playground-series-s5e6/test.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-28T20:12:47.572855Z","iopub.execute_input":"2025-06-28T20:12:47.573143Z","iopub.status.idle":"2025-06-28T20:12:49.302407Z","shell.execute_reply.started":"2025-06-28T20:12:47.573123Z","shell.execute_reply":"2025-06-28T20:12:49.301428Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Explore data\ntrain_df.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-28T20:12:51.566499Z","iopub.execute_input":"2025-06-28T20:12:51.566863Z","iopub.status.idle":"2025-06-28T20:12:51.604401Z","shell.execute_reply.started":"2025-06-28T20:12:51.566835Z","shell.execute_reply":"2025-06-28T20:12:51.603158Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-28T20:12:55.597011Z","iopub.execute_input":"2025-06-28T20:12:55.597367Z","iopub.status.idle":"2025-06-28T20:12:55.806309Z","shell.execute_reply.started":"2025-06-28T20:12:55.597312Z","shell.execute_reply":"2025-06-28T20:12:55.805464Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-28T20:12:57.895833Z","iopub.execute_input":"2025-06-28T20:12:57.896244Z","iopub.status.idle":"2025-06-28T20:12:58.047200Z","shell.execute_reply.started":"2025-06-28T20:12:57.896212Z","shell.execute_reply":"2025-06-28T20:12:58.046315Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df['Fertilizer Name'].unique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-28T20:13:00.090073Z","iopub.execute_input":"2025-06-28T20:13:00.090410Z","iopub.status.idle":"2025-06-28T20:13:00.138633Z","shell.execute_reply.started":"2025-06-28T20:13:00.090385Z","shell.execute_reply":"2025-06-28T20:13:00.137866Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df.groupby('Fertilizer Name')[['Temparature','Humidity','Moisture' ,'Phosphorous', 'Nitrogen', 'Potassium']].mean()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-28T20:13:06.200843Z","iopub.execute_input":"2025-06-28T20:13:06.201175Z","iopub.status.idle":"2025-06-28T20:13:06.310622Z","shell.execute_reply.started":"2025-06-28T20:13:06.201150Z","shell.execute_reply":"2025-06-28T20:13:06.309723Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"categorical_cols = ['Soil Type', 'Crop Type']\n\nfor col in categorical_cols:\n    plt.figure(figsize=(10, 5))\n    ax = sns.countplot(x=col, hue='Fertilizer Name', data=train_df)\n    plt.title(f'{col} Distribution by Fertilizer')\n    plt.xticks(rotation=45)\n    plt.tight_layout()\n\n    # Move legend outside\n    ax.legend(title='Fertilizer Name', bbox_to_anchor=(1.05, 1), loc='upper left')\n    \n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-28T20:13:13.894935Z","iopub.execute_input":"2025-06-28T20:13:13.895250Z","iopub.status.idle":"2025-06-28T20:13:16.955631Z","shell.execute_reply.started":"2025-06-28T20:13:13.895226Z","shell.execute_reply":"2025-06-28T20:13:16.954755Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"numerical_cols = ['Temparature', 'Humidity', 'Moisture', 'Nitrogen', 'Potassium', 'Phosphorous']\n\nfor col in numerical_cols:\n    plt.figure(figsize=(10, 5))\n    sns.boxplot(x='Fertilizer Name', y=col, data=train_df)\n    plt.title(f'{col} Distribution by Fertilizer')\n    plt.xticks(rotation=45)\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-28T20:13:54.698213Z","iopub.execute_input":"2025-06-28T20:13:54.699192Z","iopub.status.idle":"2025-06-28T20:13:58.309944Z","shell.execute_reply.started":"2025-06-28T20:13:54.699160Z","shell.execute_reply":"2025-06-28T20:13:58.309015Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"corr_matrix = train_df[numerical_cols].corr()\n\nplt.figure(figsize=(10, 8))\nsns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)\nplt.title('Correlation Matrix of Numerical Features')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-28T20:14:01.336055Z","iopub.execute_input":"2025-06-28T20:14:01.336391Z","iopub.status.idle":"2025-06-28T20:14:01.796977Z","shell.execute_reply.started":"2025-06-28T20:14:01.336361Z","shell.execute_reply":"2025-06-28T20:14:01.796085Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Remove target from training set\nX = train_df.drop('Fertilizer Name', axis=1)\ny = train_df['Fertilizer Name']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-28T20:15:07.224949Z","iopub.execute_input":"2025-06-28T20:15:07.225241Z","iopub.status.idle":"2025-06-28T20:15:07.256919Z","shell.execute_reply.started":"2025-06-28T20:15:07.225222Z","shell.execute_reply":"2025-06-28T20:15:07.256018Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Encode categorical target\nle = LabelEncoder()\ny_encoded = le.fit_transform(y)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-28T20:15:20.522234Z","iopub.execute_input":"2025-06-28T20:15:20.522595Z","iopub.status.idle":"2025-06-28T20:15:20.665508Z","shell.execute_reply.started":"2025-06-28T20:15:20.522572Z","shell.execute_reply":"2025-06-28T20:15:20.664673Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Split training data to train model\nX_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size = 0.2, stratify = y, random_state = 10)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Block of code to test different feature engineered groups\nX_train = X_train.copy()\nX_train['Soil Crop'] = X_train['Soil Type']+'_'+X_train['Crop Type']\n\nX_test = X_test.copy()\nX_test['Soil Crop'] = X_test['Soil Type']+'_'+X_test['Crop Type']","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Separate categorical an numerical columns for training model\nte_cols = ['Soil Type','Crop Type', 'Soil Crop']\nall_num_cols = [ 'Moisture', 'Nitrogen', 'Potassium', 'Phosphorous']","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Encode categorical columns \nte = TargetEncoder(cols=te_cols, smoothing=10)\nX_train[te_cols] = te.fit_transform(X_train[te_cols], y_train)\nX_test[te_cols] = te.transform(X_test[te_cols])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Pipeline for scaling\nscaler_pipeline = Pipeline(steps=[\n    ('scaler', StandardScaler())\n])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Apply scaling to numerical and target encoded categorical features\ncol_trans = ColumnTransformer(transformers=[\n    ('num_pipeline', scaler_pipeline, all_num_cols),\n    ('te_cols', scaler_pipeline, te_cols)\n],\n    remainder = 'drop')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Pipeline for handling preprocessing of scaling numerical and encoded features\npipeline = Pipeline(steps=[\n    ('preprocessing', col_trans)\n])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Apply preprocessing pipeline: fit on training data, transform both sets\nX_train_processed = pipeline.fit_transform(X_train)\nX_test_processed = pipeline.transform(X_test)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Metric function for MAP@3 calculation\ndef mapk_metric(y_true, y_pred_topk, k=3):\n    return np.mean([\n        1.0 / (pred[:k].index(true) + 1) if true in pred[:k] else 0.0\n        for true, pred in zip(y_true, y_pred_topk)\n    ])\n\n# custom MAP@3 scoring function for gridsearchCV\ndef map3_scorer(estimator, X, y):\n    proba = estimator.predict_proba(X)  \n    top_3 = np.argsort(proba, axis=1)[:, -3:][:, ::-1] \n    top_3_list = top_3.tolist()\n    return mapk_metric(y, top_3_list, k=3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T16:44:16.283070Z","iopub.execute_input":"2025-06-16T16:44:16.283475Z","iopub.status.idle":"2025-06-16T16:44:16.290757Z","shell.execute_reply.started":"2025-06-16T16:44:16.283422Z","shell.execute_reply":"2025-06-16T16:44:16.289406Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Model 1\nlgbm = LGBMClassifier(random_state=10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T16:44:16.291717Z","iopub.execute_input":"2025-06-16T16:44:16.291986Z","iopub.status.idle":"2025-06-16T16:44:16.309373Z","shell.execute_reply.started":"2025-06-16T16:44:16.291964Z","shell.execute_reply":"2025-06-16T16:44:16.308244Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# These tuned parameters gave best results\nparam_grid_lgbm = {\n    'n_estimators': [500],\n    'learning_rate': [0.05],\n    'num_leaves': [ 127],\n    'min_data_in_leaf': [50],\n    'feature_fraction': [0.6],\n    'bagging_fraction': [0.8],\n    'bagging_freq': [1],\n    'min_gain_to_split': [0],\n    'lambda_l2': [1]\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T16:44:16.330798Z","iopub.execute_input":"2025-06-16T16:44:16.331141Z","iopub.status.idle":"2025-06-16T16:44:16.350609Z","shell.execute_reply.started":"2025-06-16T16:44:16.331106Z","shell.execute_reply":"2025-06-16T16:44:16.349289Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Gridsearch to find best hyperparameters with map@3 as scoring metric\nlgbm_cv = GridSearchCV(lgbm, param_grid_lgbm, cv=3, scoring=map3_scorer, n_jobs=-1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T20:39:25.480201Z","iopub.execute_input":"2025-06-13T20:39:25.480534Z","iopub.status.idle":"2025-06-13T20:39:25.485822Z","shell.execute_reply.started":"2025-06-13T20:39:25.480508Z","shell.execute_reply":"2025-06-13T20:39:25.484729Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Fit model\nlgbm_cv.fit(X_train_processed, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T20:39:30.795275Z","iopub.execute_input":"2025-06-13T20:39:30.795679Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Returns best parameters from GridsearchCV\nlgbm_cv.best_params_","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Best score from model\nlgbm_cv.best_score_","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Used to determine feature engineered columns with the most impact\n\n# from sklearn.inspection import permutation_importance\n\n# # Run permutation importance using best estimator\n# result = permutation_importance(\n#     lgbm_cv.best_estimator_,  \n#     X_test_processed,\n#     y_test,\n#     n_repeats=10,\n#     random_state=10,\n#     n_jobs=-1\n# )\n\n# # Handle feature names: If pipeline removed names, get them manually\n# try:\n#     feature_names = col_trans.get_feature_names_out()\n# except:\n#     feature_names = [f'Feature {i}' for i in range(X_test_processed.shape[1])]\n\n# # Create DataFrame with results\n# importance_df = pd.DataFrame({\n#     'Feature': feature_names,\n#     'Importance Mean': result.importances_mean,\n#     'Importance Std': result.importances_std\n# }).sort_values(by='Importance Mean', ascending=False)\n\n# # Plot\n# importance_df.head(20).plot(\n#     kind='barh',\n#     x='Feature',\n#     y='Importance Mean',\n#     xerr='Importance Std',\n#     title='Top 20 Features by Permutation Importance',\n#     figsize=(10, 8)\n# )\n# plt.gca().invert_yaxis()\n# plt.tight_layout()\n# plt.show()\n\n# # get top 10 features\n# top_features = importance_df.head(10)['Feature'].tolist()\n# print(\"Top 10 Features:\", top_features)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Model 2\nxgb = XGBClassifier(random_state=10, tree_method = 'hist')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# These tuned parameters gave best results\nparam_grid_xgb = {\n    'n_estimators': [500],\n    'max_depth': [8],               \n    'learning_rate': [0.1],         \n    'subsample': [0.8],             \n    'min_child_weight': [4],        \n    'colsample_bytree': [0.4],      \n    'gamma': [0],       \n    'lambda': [5],             \n    'alpha': [1], \n}     ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Gridsearch to find best hyperparameters with map@3 as scoring metric\nxgb_cv = GridSearchCV(xgb, param_grid_xgb, cv=3, scoring=map3_scorer, n_jobs=-1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Fit model\nxgb_cv.fit(X_train_processed, y_train)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Returns best parameters from GridsearchCV\nxgb_cv.best_params_","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Best score from model\nxgb_cv.best_score_","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Use full training data for stratifiedKFold\nX_full = train_df.drop('Fertilizer Name', axis=1).copy()\ny_full = train_df['Fertilizer Name']\ny_full_encoded = le.transform(y_full)\n\n# Add feature engineered column to full training data\nX_full['Soil Crop'] = X_full['Soil Type'] + '_' + X_full['Crop Type']\n\n# Target encoding on full training set only\nte_full = TargetEncoder(cols=te_cols, smoothing=10)\nX_full[te_cols] = te_full.fit_transform(X_full[te_cols], y_full_encoded)\n\n# Preprocess features for full training data\nX_full_processed = pipeline.fit_transform(X_full)\n\n# Add feature engineered column, target encode, and preprocess TEST data\ntest_df = test_df.copy()\ntest_df['Soil Crop'] = test_df['Soil Type'] + '_' + test_df['Crop Type']\ntest_df[te_cols] = te_full.transform(test_df[te_cols])\ntest_processed = pipeline.transform(test_df)\n\n# StratifiedKFold 5 fold cross validation\nkf = StratifiedKFold(n_splits=5, shuffle=True, random_state=10)\ntest_preds = np.zeros((test_processed.shape[0], len(le.classes_)))  \n\n# Train and predict for each fold then run on test set\nfor fold, (train_idx, val_idx) in enumerate(kf.split(X_full_processed, y_full_encoded)):\n    print(f\" Training fold {fold+1}\")\n    \n    X_train_fold = X_full_processed[train_idx]\n    y_train_fold = y_full_encoded[train_idx]\n\n    model = VotingClassifier(\n        estimators=[\n            ('xgb', XGBClassifier(**xgb_cv.best_params_, use_label_encoder=False, eval_metric='mlogloss', verbosity=0)),\n            ('lgbm', LGBMClassifier(**lgbm_cv.best_params_))\n        ],\n        voting='soft',\n        n_jobs=-1\n    )\n\n    model.fit(X_train_fold, y_train_fold)\n\n    # Average test predictions\n    test_preds += model.predict_proba(test_processed) / 5\n\n# Get top-3 predictions\ntop_3_indices = np.argsort(test_preds, axis=1)[:, -3:][:, ::-1]\n\n# # Convert label-encoded indices of top-3 predictions back to original class labels\ntop_3_labels = np.array([le.inverse_transform(top_3_indices[:, i]) for i in range(3)]).T\n\n# Format predictions into spaced strings\nfinal_preds = [' '.join(row) for row in top_3_labels]\n\n# Create submission file\nsubmission = pd.DataFrame({\n    'id': test_df['id'],\n    'Fertilizer Name': final_preds\n})\n\nsubmission.to_csv('submission_simple_ensemble.csv', index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}